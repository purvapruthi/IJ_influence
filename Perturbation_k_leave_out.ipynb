{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import torch.autograd as autograd\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from logReg import LogitReg\n",
    "from torch.nn import Parameter\n",
    "from influence import *\n",
    "from util import *\n",
    "import hessian as hess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Training loss 0.41001251339912415\n",
      "a 53993.0 b 60000\n",
      "Training accuracy 0.8998833298683167\n",
      "Test loss 0.3923059105873108\n",
      "a 9056.0 b 10000\n",
      "Test accuracy 0.9056000113487244\n"
     ]
    }
   ],
   "source": [
    "'''training_data = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True),shuffle=True)\n",
    "test_data =  torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True),shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "X_train = training_data.dataset.train_data.data.reshape(-1,784).type(torch.FloatTensor)/255\n",
    "y_train = training_data.dataset.train_labels.data\n",
    "X_test = test_data.dataset.test_data.data.reshape(-1,784).type(torch.FloatTensor)/255\n",
    "y_test = test_data.dataset.test_labels\n",
    "\n",
    "\n",
    "np.savez(\"../data/training_data.npz\", X=X_train, Y= y_train)\n",
    "np.savez(\"../data/test_data.npz\", X=X_test, Y= y_test)'''\n",
    "\n",
    "X_train = torch.from_numpy(np.load(\"../data/training_data.npz\")[\"X\"])\n",
    "y_train = torch.from_numpy(np.load(\"../data/training_data.npz\")[\"Y\"])\n",
    "X_test = torch.from_numpy(np.load(\"../data/test_data.npz\")[\"X\"])\n",
    "y_test = torch.from_numpy(np.load(\"../data/test_data.npz\")[\"Y\"])\n",
    "\n",
    "\n",
    "\n",
    "max_iter = 100\n",
    "D_in = X_train.shape[1]\n",
    "D_out = 10\n",
    "N = X_train.shape[0]\n",
    "weight_decay = 0.01\n",
    "\n",
    "cls = LogitReg(max_iter, D_in, D_out, N, weight_decay)\n",
    "cls.fit(X_train,y_train)\n",
    "print(\"Training loss {}\".format(cls.loss_fn(X_train, y_train)))\n",
    "print( \"Training accuracy {}\". format( cls.score(X_train,y_train)))\n",
    "print( \"Test loss {}\". format( cls.loss_fn(X_test,y_test)))\n",
    "print( \"Test accuracy {}\". format( cls.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01\n",
      "\n",
      "original_prediction tensor([1]) original label tensor([8])\n",
      "perturbed_prediction tensor([8]) original label tensor([8])\n",
      "original_image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perturbed_image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.856045\n",
      "         Iterations: 7\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 102\n",
      "         Hessian evaluations: 74\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "original_prediction on retrained model {} original label {} tensor([1]) tensor([8])\n",
      "perturbed_prediction on retrained model {} original label {} tensor([8]) tensor([8])\n",
      "Saving_Results at i 0\n",
      "Predicted params diff 0.0002868695301003754 actual params diff 0.005796543788164854\n",
      "Predicted loss diff -0.0005199935913085937 actual loss diff 0.00015044212341308594\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.574281\n",
      "         Iterations: 8\n",
      "         Function evaluations: 133\n",
      "         Gradient evaluations: 128\n",
      "         Hessian evaluations: 88\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.027247\n",
      "         Iterations: 7\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 73\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.335271\n",
      "         Iterations: 7\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 84\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.497782\n",
      "         Iterations: 8\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 88\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.254096\n",
      "         Iterations: 10\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 131\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.955545\n",
      "         Iterations: 9\n",
      "         Function evaluations: 71\n",
      "         Gradient evaluations: 68\n",
      "         Hessian evaluations: 102\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.467311\n",
      "         Iterations: 7\n",
      "         Function evaluations: 69\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 75\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.092232\n",
      "         Iterations: 8\n",
      "         Function evaluations: 125\n",
      "         Gradient evaluations: 118\n",
      "         Hessian evaluations: 104\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.151526\n",
      "         Iterations: 8\n",
      "         Function evaluations: 146\n",
      "         Gradient evaluations: 141\n",
      "         Hessian evaluations: 100\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.126800\n",
      "         Iterations: 7\n",
      "         Function evaluations: 138\n",
      "         Gradient evaluations: 132\n",
      "         Hessian evaluations: 97\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.784243\n",
      "         Iterations: 9\n",
      "         Function evaluations: 121\n",
      "         Gradient evaluations: 118\n",
      "         Hessian evaluations: 103\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.213034\n",
      "         Iterations: 7\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 77\n",
      "         Hessian evaluations: 82\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [61] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.865418\n",
      "         Iterations: 8\n",
      "         Function evaluations: 128\n",
      "         Gradient evaluations: 123\n",
      "         Hessian evaluations: 98\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.464026\n",
      "         Iterations: 9\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 102\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Optimization terminated successfully.\n",
      "         Current function value: -2.269140\n",
      "         Iterations: 10\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 29\n",
      "         Hessian evaluations: 101\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.502587\n",
      "         Iterations: 9\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 71\n",
      "         Hessian evaluations: 86\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.303727\n",
      "         Iterations: 7\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 82\n",
      "         Hessian evaluations: 79\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.981534\n",
      "         Iterations: 8\n",
      "         Function evaluations: 134\n",
      "         Gradient evaluations: 128\n",
      "         Hessian evaluations: 90\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.710271\n",
      "         Iterations: 7\n",
      "         Function evaluations: 59\n",
      "         Gradient evaluations: 54\n",
      "         Hessian evaluations: 76\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.814534\n",
      "         Iterations: 9\n",
      "         Function evaluations: 139\n",
      "         Gradient evaluations: 134\n",
      "         Hessian evaluations: 116\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [62] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.298424\n",
      "         Iterations: 8\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 138\n",
      "         Hessian evaluations: 114\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.259708\n",
      "         Iterations: 8\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 83\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.887036\n",
      "         Iterations: 7\n",
      "         Function evaluations: 64\n",
      "         Gradient evaluations: 59\n",
      "         Hessian evaluations: 78\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.293023\n",
      "         Iterations: 7\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 82\n",
      "         Hessian evaluations: 71\n",
      "torch.Size([60000, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.128867\n",
      "         Iterations: 10\n",
      "         Function evaluations: 103\n",
      "         Gradient evaluations: 101\n",
      "         Hessian evaluations: 120\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [62] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.603727\n",
      "         Iterations: 10\n",
      "         Function evaluations: 72\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 118\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.220172\n",
      "         Iterations: 9\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 86\n",
      "         Hessian evaluations: 114\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.282237\n",
      "         Iterations: 9\n",
      "         Function evaluations: 147\n",
      "         Gradient evaluations: 141\n",
      "         Hessian evaluations: 118\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.577604\n",
      "         Iterations: 9\n",
      "         Function evaluations: 76\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 114\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.151691\n",
      "         Iterations: 8\n",
      "         Function evaluations: 73\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 89\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.923134\n",
      "         Iterations: 8\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 87\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.362877\n",
      "         Iterations: 8\n",
      "         Function evaluations: 115\n",
      "         Gradient evaluations: 112\n",
      "         Hessian evaluations: 91\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.125084\n",
      "         Iterations: 9\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 19\n",
      "         Hessian evaluations: 106\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.609584\n",
      "         Iterations: 8\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 93\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.128543\n",
      "         Iterations: 9\n",
      "         Function evaluations: 134\n",
      "         Gradient evaluations: 128\n",
      "         Hessian evaluations: 104\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.401291\n",
      "         Iterations: 9\n",
      "         Function evaluations: 90\n",
      "         Gradient evaluations: 87\n",
      "         Hessian evaluations: 110\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.878891\n",
      "         Iterations: 7\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 87\n",
      "         Hessian evaluations: 78\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [69] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.608652\n",
      "         Iterations: 7\n",
      "         Function evaluations: 69\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 72\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.178648\n",
      "         Iterations: 8\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 95\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.091652\n",
      "         Iterations: 6\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 64\n",
      "         Hessian evaluations: 72\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.645593\n",
      "         Iterations: 9\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 27\n",
      "         Hessian evaluations: 114\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.292289\n",
      "         Iterations: 10\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 24\n",
      "         Hessian evaluations: 118\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1.208655\n",
      "         Iterations: 10\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 29\n",
      "         Hessian evaluations: 111\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.663926\n",
      "         Iterations: 8\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 86\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.888070\n",
      "         Iterations: 9\n",
      "         Function evaluations: 99\n",
      "         Gradient evaluations: 96\n",
      "         Hessian evaluations: 104\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [69] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.250664\n",
      "         Iterations: 7\n",
      "         Function evaluations: 72\n",
      "         Gradient evaluations: 67\n",
      "         Hessian evaluations: 84\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.074945\n",
      "         Iterations: 7\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 89\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.306531\n",
      "         Iterations: 8\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 93\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.979787\n",
      "         Iterations: 8\n",
      "         Function evaluations: 80\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 87\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [69] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.097829\n",
      "         Iterations: 7\n",
      "         Function evaluations: 80\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 77\n",
      "torch.Size([60000, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.715480\n",
      "         Iterations: 9\n",
      "         Function evaluations: 88\n",
      "         Gradient evaluations: 85\n",
      "         Hessian evaluations: 111\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.920600\n",
      "         Iterations: 7\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 81\n",
      "         Hessian evaluations: 83\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.398752\n",
      "         Iterations: 8\n",
      "         Function evaluations: 157\n",
      "         Gradient evaluations: 151\n",
      "         Hessian evaluations: 100\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.226626\n",
      "         Iterations: 10\n",
      "         Function evaluations: 144\n",
      "         Gradient evaluations: 139\n",
      "         Hessian evaluations: 123\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.247189\n",
      "         Iterations: 7\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 86\n",
      "         Hessian evaluations: 83\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.564525\n",
      "         Iterations: 8\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 92\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [63] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.159523\n",
      "         Iterations: 10\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 89\n",
      "         Hessian evaluations: 124\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.707572\n",
      "         Iterations: 8\n",
      "         Function evaluations: 88\n",
      "         Gradient evaluations: 85\n",
      "         Hessian evaluations: 94\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.034516\n",
      "         Iterations: 8\n",
      "         Function evaluations: 153\n",
      "         Gradient evaluations: 148\n",
      "         Hessian evaluations: 94\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.117919\n",
      "         Iterations: 9\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 74\n",
      "         Hessian evaluations: 110\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.983678\n",
      "         Iterations: 8\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 96\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.424421\n",
      "         Iterations: 8\n",
      "         Function evaluations: 141\n",
      "         Gradient evaluations: 134\n",
      "         Hessian evaluations: 99\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.294181\n",
      "         Iterations: 7\n",
      "         Function evaluations: 76\n",
      "         Gradient evaluations: 71\n",
      "         Hessian evaluations: 84\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.136619\n",
      "         Iterations: 8\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 77\n",
      "         Hessian evaluations: 104\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.365238\n",
      "         Iterations: 8\n",
      "         Function evaluations: 80\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 87\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.605828\n",
      "         Iterations: 10\n",
      "         Function evaluations: 128\n",
      "         Gradient evaluations: 124\n",
      "         Hessian evaluations: 119\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.020313\n",
      "         Iterations: 7\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 76\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.101390\n",
      "         Iterations: 7\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 81\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.542721\n",
      "         Iterations: 10\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 21\n",
      "         Hessian evaluations: 113\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.080981\n",
      "         Iterations: 8\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 86\n",
      "         Hessian evaluations: 103\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.456782\n",
      "         Iterations: 9\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 138\n",
      "         Hessian evaluations: 118\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.930941\n",
      "         Iterations: 10\n",
      "         Function evaluations: 134\n",
      "         Gradient evaluations: 131\n",
      "         Hessian evaluations: 115\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.995161\n",
      "         Iterations: 9\n",
      "         Function evaluations: 95\n",
      "         Gradient evaluations: 92\n",
      "         Hessian evaluations: 120\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.514310\n",
      "         Iterations: 9\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 107\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.107924\n",
      "         Iterations: 7\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 78\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.440452\n",
      "         Iterations: 8\n",
      "         Function evaluations: 144\n",
      "         Gradient evaluations: 139\n",
      "         Hessian evaluations: 93\n",
      "torch.Size([60000, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.240926\n",
      "         Iterations: 9\n",
      "         Function evaluations: 163\n",
      "         Gradient evaluations: 157\n",
      "         Hessian evaluations: 90\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.402827\n",
      "         Iterations: 11\n",
      "         Function evaluations: 155\n",
      "         Gradient evaluations: 153\n",
      "         Hessian evaluations: 155\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.796857\n",
      "         Iterations: 8\n",
      "         Function evaluations: 73\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 92\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1.566937\n",
      "         Iterations: 11\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 25\n",
      "         Hessian evaluations: 114\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.294571\n",
      "         Iterations: 8\n",
      "         Function evaluations: 114\n",
      "         Gradient evaluations: 108\n",
      "         Hessian evaluations: 90\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [69] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.420738\n",
      "         Iterations: 8\n",
      "         Function evaluations: 134\n",
      "         Gradient evaluations: 129\n",
      "         Hessian evaluations: 90\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.375609\n",
      "         Iterations: 8\n",
      "         Function evaluations: 156\n",
      "         Gradient evaluations: 151\n",
      "         Hessian evaluations: 93\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.596602\n",
      "         Iterations: 9\n",
      "         Function evaluations: 95\n",
      "         Gradient evaluations: 92\n",
      "         Hessian evaluations: 114\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.682181\n",
      "         Iterations: 8\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 78\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [65] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.391519\n",
      "         Iterations: 8\n",
      "         Function evaluations: 144\n",
      "         Gradient evaluations: 139\n",
      "         Hessian evaluations: 93\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.247048\n",
      "         Iterations: 9\n",
      "         Function evaluations: 159\n",
      "         Gradient evaluations: 154\n",
      "         Hessian evaluations: 122\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.348880\n",
      "         Iterations: 9\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 78\n",
      "         Hessian evaluations: 117\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.399181\n",
      "         Iterations: 7\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 77\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.423347\n",
      "         Iterations: 7\n",
      "         Function evaluations: 68\n",
      "         Gradient evaluations: 63\n",
      "         Hessian evaluations: 73\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -3.402329\n",
      "         Iterations: 8\n",
      "         Function evaluations: 73\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 89\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.623696\n",
      "         Iterations: 8\n",
      "         Function evaluations: 134\n",
      "         Gradient evaluations: 127\n",
      "         Hessian evaluations: 105\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.386368\n",
      "         Iterations: 10\n",
      "         Function evaluations: 170\n",
      "         Gradient evaluations: 166\n",
      "         Hessian evaluations: 112\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [64] iter.\n",
      "After training with LBFGS: \n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1.873537\n",
      "         Iterations: 11\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 39\n",
      "         Hessian evaluations: 112\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [68] iter.\n",
      "After training with LBFGS: \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.169075\n",
      "         Iterations: 9\n",
      "         Function evaluations: 76\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 115\n",
      "torch.Size([60000, 784])\n",
      "LBFGS training took [66] iter.\n",
      "After training with LBFGS: \n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.01\n",
    "while( epsilon <= 0.25):\n",
    "    influence_perurbation(cls, X_train, y_train, X_test, y_test, num_to_remove=500, verify_influence=True, \n",
    "                      epsilon =epsilon, weight = 1, load_refresh=True)\n",
    "    epsilon += 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_perurbation_k_leave_out( model, X_train, y_train, X_test, y_test, num_to_remove=5, random_seed=7, \n",
    "                                      verify_influence = False, epsilon = 0.25, weight = 0):\n",
    "        test_idx = 8\n",
    "        N = model.num_train_examples\n",
    "        actual_params_diff = np.zeros(n_trials)\n",
    "        predicted_params_diff = np.zeros(n_trials)\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            indices_to_remove = np.random.choice(N, num_to_remove)\n",
    "           \n",
    "            X_pert = torch.zeros(num_to_remove, X_train.shape)\n",
    "            for i in range(num_to_remove):\n",
    "                tr_idx = indices_to_remove[i]\n",
    "                X_tr, y_tr, X_te, y_te = split_data( tr_idx, test_idx, X_train, y_train, X_test, y_test)\n",
    "\n",
    "                h = hess.Hessian( model, X_train, y_train )\n",
    "                h.initialize(X_train, y_train)\n",
    "                train_grad, train_loss = h.get_loss_gradient(X_tr, y_tr)\n",
    "\n",
    "                X_pert[i,:] = perturbation( model, X_tr, y_tr, epsilon=epsilon, weight=weight )\n",
    "\n",
    "            X_tr, y_tr, X_te, y_te = split_data( indices_to_remove, test_idx, X_train, y_train, X_test, y_test)\n",
    "\n",
    "            all_train_grad, train_loss = h.get_loss_gradient(X_tr, y_tr)\n",
    "            perturb_train_grad, pert_train_loss = h.get_loss_gradient(X_pert, y_tr)\n",
    "\n",
    "            diff_v = perturb_train_grad - train_grad\n",
    "\n",
    "            filename = \"../data/perturbation/hp_inv_pert_k\" + str(num_to_remove) +\".npz\"\n",
    "            my_file = Path(filename)\n",
    "\n",
    "            if my_file.is_file() and load_refresh == False:\n",
    "                print( \"Loading hvp inverse from file {}\".format(filename))\n",
    "                hvp = np.load(filename)[\"h\"].item()[0]\n",
    "            else:\n",
    "                v = diff_v.detach().numpy()\n",
    "                print(\"Calculating HVP inverse\")\n",
    "                hvp = h.get_inverse_hvp_cg(v, max_iterations = 100)\n",
    "                np.savez(filename, h = hvp)\n",
    "\n",
    "            print(\"Removing original training point and adding perturbation\\n\")\n",
    "\n",
    "            ans = np.linalg.norm(np.array(hvp)/N)\n",
    "            print(ans)\n",
    "            predicted_params_diff[trial] = ans\n",
    "\n",
    "            if( verify_influence):\n",
    "                cls_leave = LogitReg(model.iterations, model.D_in, model.D_out, N, model.weight_decay)\n",
    "                X = X_train\n",
    "                X[indices_to_remove, :] = X_pert.detach()\n",
    "                cls_leave.fit( X, y_train)\n",
    "                actual_difference = cls_leave.fc1.weight.view(-1) - model.fc1.weight.view(-1)\n",
    "                actual_params_diff[trial] = torch.norm(actual_difference).detach().numpy()\n",
    "                print( \"Predicted loss {} actual loss {}\".format(predicted_params_diff[trial], actual_params_diff[trial]))\n",
    "\n",
    "        np.savez(\"../data/perturbation/loss_diffs_perturb.npz\",r = {\"predicted_loss\":predicted_params_diff, \"actual_loss\": actual_params_diff})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 10\n",
    "while( count >=10 ):\n",
    "    print(\"Leave-out-k-{}\".format(count))\n",
    "    influence_k_leave_out(cls, X_train, y_train, X_test, y_test, n_trials=1, k=count)\n",
    "    count = count - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.load(\"../data/loss_diffs_75_8.npz\")[\"r\"]\n",
    "plt.plot(K.item()['predicted_loss'], K.item()['actual_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
