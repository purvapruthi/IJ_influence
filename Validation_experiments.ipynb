{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import torch.autograd as autograd\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from logReg import LogitReg\n",
    "from torch.nn import Parameter\n",
    "from influence import influence\n",
    "from scipy.stats.stats import pearsonr\n",
    "import hessian as hess\n",
    "from util import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [67] iter.\n",
      "After training with LBFGS: \n",
      "Training loss 0.41001251339912415\n",
      "a 53993.0 b 60000\n",
      "Training accuracy 0.8998833298683167\n",
      "Test loss 0.3923059105873108\n",
      "a 9056.0 b 10000\n",
      "Test accuracy 0.9056000113487244\n"
     ]
    }
   ],
   "source": [
    "'''training_data = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True),shuffle=True)\n",
    "test_data =  torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True),shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "X_train = training_data.dataset.train_data.data.reshape(-1,784).type(torch.FloatTensor)/255\n",
    "y_train = training_data.dataset.train_labels.data\n",
    "X_test = test_data.dataset.test_data.data.reshape(-1,784).type(torch.FloatTensor)/255\n",
    "y_test = test_data.dataset.test_labels\n",
    "\n",
    "\n",
    "np.savez(\"../data/training_data.npz\", X=X_train, Y= y_train)\n",
    "np.savez(\"../data/test_data.npz\", X=X_test, Y= y_test)'''\n",
    "\n",
    "X_train = torch.from_numpy(np.load(\"../data/training_data.npz\")[\"X\"])\n",
    "y_train = torch.from_numpy(np.load(\"../data/training_data.npz\")[\"Y\"])\n",
    "X_test = torch.from_numpy(np.load(\"../data/test_data.npz\")[\"X\"])\n",
    "y_test = torch.from_numpy(np.load(\"../data/test_data.npz\")[\"Y\"])\n",
    "\n",
    "\n",
    "\n",
    "max_iter = 100\n",
    "D_in = X_train.shape[1]\n",
    "D_out = 10\n",
    "N = X_train.shape[0]\n",
    "weight_decay = 0.01\n",
    "\n",
    "cls = LogitReg(max_iter, D_in, D_out, N, weight_decay)\n",
    "cls.fit(X_train,y_train)\n",
    "print(\"Training loss {}\".format(cls.loss_fn(X_train, y_train)))\n",
    "print( \"Training accuracy {}\". format( cls.score(X_train,y_train)))\n",
    "print( \"Test loss {}\". format( cls.loss_fn(X_test,y_test)))\n",
    "print( \"Test accuracy {}\". format( cls.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence(cls, X_train, y_train, X_test, y_test, max_inf = True, n_test_indices = 5, num_to_remove = 500, n_max_inf = 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.load(\"../data/loss_diffs_8.npz\")[\"r\"]\n",
    "plt.plot(K.item()['predicted_loss'], K.item()['actual_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(K.item()['predicted_loss'],K.item()['actual_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
